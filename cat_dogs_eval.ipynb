{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cat and Dogs using CNN & Trasformers\n",
    "\n",
    "The goal of this notebook is to analyze and compare two different approaches to image recognition. The first model we will examine is based on Convolutional Neural Networks (CNNs), a well-established and effective technique for image processing. The second model, on the other hand, employs Visual Transformers, a more recent architecture that leverages attention mechanisms to capture spatial relationships between pixels. By comparing these two models, we will assess their performance and gain insights into their respective strengths and weaknesses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feaute Analysis & Transformation\n",
    "\n",
    "The first step is to analyze the features of the available data. Specifically, we will examine the dataset distribution to understand the number of images, the classes present, and any potential imbalances between categories. This preliminary analysis will help us define the best strategy for the model training phase, optimizing the split between training, validation, and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually we are going to use a easy dataset to fit the model on mine cpu.\n",
    " -> Import dataset from Kaggle:\n",
    " [CAT & DOGS](https://www.kaggle.com/datasets/d4rklucif3r/cat-and-dogs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marco\\miniconda3\\envs\\gpu-tf\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\marco\\.cache\\kagglehub\\datasets\\d4rklucif3r\\cat-and-dogs\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"d4rklucif3r/cat-and-dogs\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "path = path + \"\\\\dataset\\\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of classes are:  2\n",
      "\n",
      "Total number of images in the dataset are:  8000\n",
      "MEAN number of images in each class is:  4000\n",
      "\n",
      "Number of images for each class: \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import feature_engineering as fe\n",
    "\n",
    "train_dir, _, test_dir = fe.dataset_sub_division(path)\n",
    "\n",
    "classes = fe.analisys_dataset_composition(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 files belonging to 2 classes.\n",
      "Found 2000 files belonging to 2 classes.\n",
      "Numero di classi: 2, Classi: ['cats', 'dogs']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Parametri del dataset\n",
    "img_size = (256, 256)\n",
    "batch_size = 8\n",
    "\n",
    "# Caricamento automatico delle immagini da cartelle (senza PyTorch)\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# Caricamento automatico delle immagini da cartelle (senza PyTorch)\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# Determina il numero di classi automaticamente\n",
    "num_classes = len(train_ds.class_names)\n",
    "print(f\"Numero di classi: {num_classes}, Classi: {train_ds.class_names}\")\n",
    "\n",
    "# ✅ Convertire i target in one-hot encoding\n",
    "def one_hot_encode(image, label):\n",
    "    return image, tf.one_hot(label, depth=num_classes)\n",
    "\n",
    "train_ds = train_ds.map(one_hot_encode)\n",
    "test_ds = test_ds.map(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuriamo l'esecuzione su GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.test.is_built_with_cuda())\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "class CNN_model():\n",
    "    \n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.model = keras.Sequential([\n",
    "            # Block One\n",
    "            layers.Conv2D(filters=32,\n",
    "                        kernel_size=3, \n",
    "                        activation='relu', \n",
    "                        padding='same',\n",
    "                        input_shape=[256, 256, 3]),\n",
    "            layers.MaxPool2D(),\n",
    "\n",
    "            # Block Two\n",
    "            layers.Conv2D(filters=64,\n",
    "                        kernel_size=3,\n",
    "                        activation='relu',\n",
    "                        padding='same'),\n",
    "            layers.MaxPool2D(),\n",
    "\n",
    "            # Block Three\n",
    "            layers.Conv2D(filters=128, \n",
    "                        kernel_size=3, \n",
    "                        activation='relu', \n",
    "                        padding='same'),\n",
    "            layers.Conv2D(filters=128, \n",
    "                        kernel_size=3, \n",
    "                        activation='relu', \n",
    "                        padding='same'),\n",
    "            layers.MaxPool2D(),\n",
    "\n",
    "            # Head\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(256, activation='relu'),  # Layer fully connected aggiuntivo per migliorare la capacità di apprendimento\n",
    "            layers.Dropout(0.5),  # Dropout per evitare overfitting\n",
    "            layers.Dense(num_classes, activation='softmax' if num_classes > 2 else 'sigmoid'),\n",
    "        ])\n",
    "\n",
    "        self.model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "            loss='categorical_crossentropy' if num_classes > 2 else 'binary_crossentropy',\n",
    "            metrics=['categorical_accuracy' if num_classes > 2 else 'binary_accuracy'],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 67s 60ms/step - loss: 1.3057 - binary_accuracy: 0.5906\n",
      "Epoch 2/10\n",
      " 599/1000 [================>.............] - ETA: 30s - loss: 0.6235 - binary_accuracy: 0.6522"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m CNN_model(num_classes)\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Addestramento della rete neurale\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Modifica il numero di epoche se necessario\u001b[39;49;00m\n\u001b[0;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\marco\\miniconda3\\envs\\gpu-tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\marco\\miniconda3\\envs\\gpu-tf\\lib\\site-packages\\keras\\engine\\training.py:1570\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1568\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs\n\u001b[0;32m   1569\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[1;32m-> 1570\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[0;32m   1572\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\marco\\miniconda3\\envs\\gpu-tf\\lib\\site-packages\\keras\\callbacks.py:470\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \n\u001b[0;32m    465\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[1;32m--> 470\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\marco\\miniconda3\\envs\\gpu-tf\\lib\\site-packages\\keras\\callbacks.py:317\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 317\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\marco\\miniconda3\\envs\\gpu-tf\\lib\\site-packages\\keras\\callbacks.py:340\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    337\u001b[0m     batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[1;32m--> 340\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[0;32m    343\u001b[0m     end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[1;32mc:\\Users\\marco\\miniconda3\\envs\\gpu-tf\\lib\\site-packages\\keras\\callbacks.py:388\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m    387\u001b[0m     hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m--> 388\u001b[0m     \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[0;32m    391\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[1;32mc:\\Users\\marco\\miniconda3\\envs\\gpu-tf\\lib\\site-packages\\keras\\callbacks.py:1081\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m-> 1081\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\marco\\miniconda3\\envs\\gpu-tf\\lib\\site-packages\\keras\\callbacks.py:1157\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add_seen\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1156\u001b[0m     \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\marco\\miniconda3\\envs\\gpu-tf\\lib\\site-packages\\keras\\utils\\tf_utils.py:635\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\n\u001b[0;32m    633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(t) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m--> 635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\marco\\miniconda3\\envs\\gpu-tf\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32mc:\\Users\\marco\\miniconda3\\envs\\gpu-tf\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32mc:\\Users\\marco\\miniconda3\\envs\\gpu-tf\\lib\\site-packages\\keras\\utils\\tf_utils.py:628\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m--> 628\u001b[0m         t \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;66;03m# as-is.\u001b[39;00m\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mgeneric)):\n",
      "File \u001b[1;32mc:\\Users\\marco\\miniconda3\\envs\\gpu-tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1157\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \n\u001b[0;32m   1136\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1156\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32mc:\\Users\\marco\\miniconda3\\envs\\gpu-tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1123\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1122\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1124\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Creazione del modello\n",
    "model = CNN_model(num_classes).model\n",
    "\n",
    "# Addestramento della rete neurale\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    epochs=10,  # Modifica il numero di epoche se necessario\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 5s 16ms/step - loss: 0.9721 - binary_accuracy: 0.7065\n",
      "Test Loss: 0.9721494317054749\n",
      "Test Accuracy: 0.7064999938011169\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_ds)\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu-tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
