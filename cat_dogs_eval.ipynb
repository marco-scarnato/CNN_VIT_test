{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cat and Dogs using CNN & Trasformers\n",
    "\n",
    "The goal of this notebook is to analyze and compare two different approaches to image recognition. The first model we will examine is based on Convolutional Neural Networks (CNNs), a well-established and effective technique for image processing. The second model, on the other hand, employs Visual Transformers, a more recent architecture that leverages attention mechanisms to capture spatial relationships between pixels. By comparing these two models, we will assess their performance and gain insights into their respective strengths and weaknesses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feaute Analysis & Transformation\n",
    "\n",
    "The first step is to analyze the features of the available data. Specifically, we will examine the dataset distribution to understand the number of images, the classes present, and any potential imbalances between categories. This preliminary analysis will help us define the best strategy for the model training phase, optimizing the split between training, validation, and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually we are going to use a easy dataset to fit the model on mine cpu.\n",
    " -> Import dataset from Kaggle:\n",
    " [CAT & DOGS](https://www.kaggle.com/datasets/d4rklucif3r/cat-and-dogs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marco\\miniconda3\\envs\\gpu-tf\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\marco\\.cache\\kagglehub\\datasets\\d4rklucif3r\\cat-and-dogs\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"d4rklucif3r/cat-and-dogs\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "path = path + \"\\\\dataset\\\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of classes are:  2\n",
      "\n",
      "Total number of images in the dataset are:  8000\n",
      "MEAN number of images in each class is:  4000\n",
      "\n",
      "Number of images for each class: \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import feature_engineering as fe\n",
    "\n",
    "train_dir, _, test_dir = fe.dataset_sub_division(path)\n",
    "\n",
    "classes = fe.analisys_dataset_composition(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 files belonging to 2 classes.\n",
      "Found 2000 files belonging to 2 classes.\n",
      "Numero di classi: 2, Classi: ['cats', 'dogs']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Parametri del dataset\n",
    "img_size = (256, 256)\n",
    "batch_size = 8\n",
    "\n",
    "# Caricamento automatico delle immagini da cartelle (senza PyTorch)\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# Caricamento automatico delle immagini da cartelle (senza PyTorch)\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# Determina il numero di classi automaticamente\n",
    "num_classes = len(train_ds.class_names)\n",
    "print(f\"Numero di classi: {num_classes}, Classi: {train_ds.class_names}\")\n",
    "\n",
    "# ✅ Convertire i target in one-hot encoding\n",
    "def one_hot_encode(image, label):\n",
    "    return image, tf.one_hot(label, depth=num_classes)\n",
    "\n",
    "train_ds = train_ds.map(one_hot_encode)\n",
    "test_ds = test_ds.map(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuriamo l'esecuzione su GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.test.is_built_with_cuda())\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "class CNN_model():\n",
    "    \n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.model = keras.Sequential([\n",
    "            # Block One\n",
    "            layers.Conv2D(filters=32,\n",
    "                        kernel_size=3, \n",
    "                        activation='relu', \n",
    "                        padding='same',\n",
    "                        input_shape=[256, 256, 3]),\n",
    "            layers.MaxPool2D(),\n",
    "\n",
    "            # Block Two\n",
    "            layers.Conv2D(filters=64,\n",
    "                        kernel_size=3,\n",
    "                        activation='relu',\n",
    "                        padding='same'),\n",
    "            layers.MaxPool2D(),\n",
    "\n",
    "            # Block Three\n",
    "            layers.Conv2D(filters=128, \n",
    "                        kernel_size=3, \n",
    "                        activation='relu', \n",
    "                        padding='same'),\n",
    "            layers.Conv2D(filters=128, \n",
    "                        kernel_size=3, \n",
    "                        activation='relu', \n",
    "                        padding='same'),\n",
    "            layers.MaxPool2D(),\n",
    "\n",
    "            # Head\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(256, activation='relu'),  # Layer fully connected aggiuntivo per migliorare la capacità di apprendimento\n",
    "            layers.Dropout(0.5),  # Dropout per evitare overfitting\n",
    "            layers.Dense(num_classes, activation='softmax' if num_classes > 2 else 'sigmoid'),\n",
    "        ])\n",
    "\n",
    "        self.model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "            loss='categorical_crossentropy' if num_classes > 2 else 'binary_crossentropy',\n",
    "            metrics=['categorical_accuracy' if num_classes > 2 else 'binary_accuracy'],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 46s 42ms/step - loss: 0.9750 - binary_accuracy: 0.6009\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.5779 - binary_accuracy: 0.6991\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.4828 - binary_accuracy: 0.7691\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.3748 - binary_accuracy: 0.8352\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.2618 - binary_accuracy: 0.8919\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.1921 - binary_accuracy: 0.9242\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.1449 - binary_accuracy: 0.9449\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1201 - binary_accuracy: 0.9570\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.0859 - binary_accuracy: 0.9711\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.0743 - binary_accuracy: 0.9746\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26f1075f310>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creazione del modello\n",
    "model = CNN_model(num_classes).model\n",
    "\n",
    "# Addestramento della rete neurale\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    epochs=10,  # Modifica il numero di epoche se necessario\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 3s 13ms/step - loss: 1.0218 - binary_accuracy: 0.7442\n",
      "Test Loss: 1.0218493938446045\n",
      "Test Accuracy: 0.7442499995231628\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_ds)\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu-tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
